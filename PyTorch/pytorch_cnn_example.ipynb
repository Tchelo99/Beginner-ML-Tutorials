{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8MmvtqCXX8E"
      },
      "source": [
        "# PyTorch Beginner Tutorial\n",
        "This tutorial will guide you through the fundamentals of PyTorch, from basic tensor operations to building and training neural networks. By the end, you’ll have built a simple neural network and trained it on the CIFAR-10 dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3lMs1J_XX8K"
      },
      "source": [
        "## 1. Introduction to PyTorch\n",
        "\n",
        "### What is PyTorch?\n",
        "\n",
        "PyTorch is a popular open-source deep learning framework that provides a flexible platform for research and production. It is used for building and training neural networks and offers dynamic computation graphs, which means it builds the graph on-the-fly as operations are executed. This is one of the major reasons it is widely adopted by both researchers and practitioners.\n",
        "\n",
        "### Why PyTorch?\n",
        "\n",
        "* Easy to use and debug.\n",
        "* Dynamic computation graph.\n",
        "* Seamless integration with Python.\n",
        "\n",
        "### Installation\n",
        "To install PyTorch, follow these steps:\n",
        "\n",
        "CPU Version :\n",
        "```bash\n",
        "pip install torch torchvision torchaudio\n",
        "```\n",
        "GPU Version :\n",
        "```bash\n",
        "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ESZ27-GXX8L"
      },
      "source": [
        "## 2. Tensors and Operations\n",
        "\n",
        "### What are Tensors?\n",
        "Tensors are the fundamental building blocks of PyTorch, similar to arrays in NumPy but with added functionality for GPU acceleration.\n",
        "\n",
        "Creating Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8myDFqJ_XX8N",
        "outputId": "9e661173-8da6-4dd7-b38f-3d3d57babb87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "tensor([[0.5585, 0.1291, 0.6959],\n",
            "        [0.2676, 0.6459, 0.8945],\n",
            "        [0.6091, 0.1520, 0.1587]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Create a tensor from a list\n",
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "print(x)\n",
        "\n",
        "# Create a random tensor\n",
        "random_tensor = torch.rand(3, 3)\n",
        "print(random_tensor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-L-phtlXX8P"
      },
      "source": [
        "### Basic Tensor Operations\n",
        "\n",
        "Tensors support various mathematical operations like addition, multiplication, and matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNVSPwoxXX8Q",
        "outputId": "bfa4f045-a34d-489d-a2e3-bb12dedeff2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4., 6.])\n",
            "tensor([[0.6186, 0.9029],\n",
            "        [1.3924, 0.9258]])\n"
          ]
        }
      ],
      "source": [
        "# Element-wise addition\n",
        "x = torch.tensor([1.0, 2.0])\n",
        "y = torch.tensor([3.0, 4.0])\n",
        "z = x + y\n",
        "print(z)\n",
        "\n",
        "# Matrix multiplication\n",
        "a = torch.rand(2, 3)\n",
        "b = torch.rand(3, 2)\n",
        "result = torch.matmul(a, b)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N2D296fXX8Q"
      },
      "source": [
        "## Autograd: Automatic Differentiation\n",
        "\n",
        "PyTorch's autograd feature allows automatic computation of gradients for tensor operations, which is essential for training neural networks.\n",
        "\n",
        "### Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOV8_46ZXX8R",
        "outputId": "743e1a99-aa7d-457c-9f35-003dbe43177b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.)\n"
          ]
        }
      ],
      "source": [
        "# Define a tensor with gradient tracking\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "\n",
        "# Perform some operations\n",
        "y = x ** 2\n",
        "\n",
        "# Backpropagation\n",
        "y.backward()\n",
        "\n",
        "# The gradient (dy/dx)\n",
        "print(x.grad)  # Output: 4.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuFzy8R7XX8S"
      },
      "source": [
        "## Building Neural Networks with PyTorch\n",
        "\n",
        "We’ll now move on to constructing neural networks using PyTorch’s torch.nn module.\n",
        "\n",
        "### Creating a Simple Neural Network\n",
        "Here’s how to define a simple feedforward network with one hidden layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "F0cxutoMXX8S"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Define the model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(10, 50)\n",
        "        self.fc2 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7inQOgbXX8T"
      },
      "source": [
        "## Training a Neural Network\n",
        "### Loss Function and Optimizer\n",
        "To train the model, we need to define a loss function and an optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m5nYerlhXX8T"
      },
      "outputs": [],
      "source": [
        "model = SimpleNN()\n",
        "criterion = nn.MSELoss()  # Mean Squared Error Loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIoUM_osXX8U"
      },
      "source": [
        "### Training Loop\n",
        "Here’s a simple example of a training loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2sAHBilXX8V",
        "outputId": "35ee32a8-b4e1-440d-8ecf-e4d660ff0b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.00010483173537068069\n",
            "Epoch 10, Loss: 0.0011512977071106434\n",
            "Epoch 20, Loss: 0.03400693088769913\n",
            "Epoch 30, Loss: 0.0023458541836589575\n",
            "Epoch 40, Loss: 0.07755301892757416\n",
            "Epoch 50, Loss: 0.06794198602437973\n",
            "Epoch 60, Loss: 0.03282793238759041\n",
            "Epoch 70, Loss: 0.00632517272606492\n",
            "Epoch 80, Loss: 0.14460325241088867\n",
            "Epoch 90, Loss: 2.4187691451516002e-05\n"
          ]
        }
      ],
      "source": [
        "# Example training loop\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()  # Zero the gradients\n",
        "    outputs = model(torch.rand(10))  # Dummy input\n",
        "    loss = criterion(outputs, torch.rand(1))\n",
        "    loss.backward()  # Backpropagation\n",
        "    optimizer.step()  # Update weights\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Llt4GoPPXX8W"
      },
      "source": [
        "## Dataset and DataLoader\n",
        "### Loading a Dataset\n",
        "PyTorch provides utilities for loading datasets and creating batches using DataLoader. Let’s load the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhWMYb0lXX8X",
        "outputId": "741aeb61-7b96-4963-e466-d1e7442f7a6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 15998337.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 481251.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 4410144.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4237217.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "train_data = MNIST(root='data', train=True, transform=ToTensor(), download=True)\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYfm1xGGXX8Y"
      },
      "source": [
        "## GPU Support\n",
        "Training on a GPU can significantly speed up the process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TfkmA5yRXX8Y"
      },
      "outputs": [],
      "source": [
        "# Check for GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Move model and data to GPU\n",
        "model = SimpleNN().to(device)\n",
        "x = torch.rand(10).to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IDOW2MYXX8Z"
      },
      "source": [
        "## Saving and Loading Models\n",
        "Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "w3vCWbJzXX8Z"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'model.pth')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzC8pux9XX8Z"
      },
      "source": [
        "Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWLYM6tlXX8a",
        "outputId": "9a922a72-8c1e-4604-8318-4539fd31cd61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-fe08fbba245f>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('model.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('model.pth'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CE-J2dcXX8a"
      },
      "source": [
        "## End-to-End Example: CIFAR-10 Image Classification with CNN\n",
        "### Overview\n",
        "In this section, we will build, train, and evaluate a Convolutional Neural Network (CNN) to classify images from the CIFAR-10 dataset. This project will showcase how to use PyTorch for more complex data and how to optimize model training using techniques like data augmentation and GPU acceleration.\n",
        "\n",
        "### Step 1: Loading and Preprocessing the CIFAR-10 Dataset\n",
        "We’ll start by loading the CIFAR-10 dataset using PyTorch’s torchvision module and apply transformations like normalization and data augmentation to improve model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJXa1KtGXX8a",
        "outputId": "a3c29ff5-0309-41d6-977e-3320c5b82d61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 47860565.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define transformations including normalization and data augmentation (random cropping, flipping)\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
        "    transforms.RandomCrop(32, padding=4),  # Randomly crop the image\n",
        "    transforms.ToTensor(),  # Convert the image to a tensor\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalize based on CIFAR-10 stats\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsdoPRDSXX8b"
      },
      "source": [
        "### Step 2: Building the CNN Model\n",
        "We will now define a simple CNN architecture to handle image classification. This model will include convolutional layers for feature extraction and fully connected layers for classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IMIppVJRXX8b"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the CNN model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 256)  # 128 feature maps, each 4x4 after pooling\n",
        "        self.fc2 = nn.Linear(256, 10)  # 10 output classes (CIFAR-10 classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply convolution, ReLU, and max pooling layers\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        # Flatten the tensor\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Apply fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLr72-2EXX8b"
      },
      "source": [
        "### Step 3: Setting the Loss Function and Optimizer\n",
        "We will use the CrossEntropyLoss for classification and Adam as the optimizer to update the model’s weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XVl1veVzXX8c"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model = CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nngs2ca-XX8c"
      },
      "source": [
        "### Step 4: Training the Model\n",
        "We’ll now define the training loop. This loop will:\n",
        "\n",
        "* Iterate over the training data.\n",
        "* Compute the loss and gradients.\n",
        "* Update the model weights using backpropagation.\n",
        "* Track the loss for monitoring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_QP7Z_HXX8d",
        "outputId": "ac12f50f-0b96-476e-d9e0-074e3a97ef03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100], Loss: 1.9827\n",
            "Epoch [1/10], Step [200], Loss: 1.6861\n",
            "Epoch [1/10], Step [300], Loss: 1.5659\n",
            "Epoch [1/10], Step [400], Loss: 1.5039\n",
            "Epoch [1/10], Step [500], Loss: 1.4225\n",
            "Epoch [1/10], Step [600], Loss: 1.3581\n",
            "Epoch [1/10], Step [700], Loss: 1.3538\n",
            "Epoch [2/10], Step [100], Loss: 1.2331\n",
            "Epoch [2/10], Step [200], Loss: 1.2250\n",
            "Epoch [2/10], Step [300], Loss: 1.1658\n",
            "Epoch [2/10], Step [400], Loss: 1.1643\n",
            "Epoch [2/10], Step [500], Loss: 1.1220\n",
            "Epoch [2/10], Step [600], Loss: 1.1152\n",
            "Epoch [2/10], Step [700], Loss: 1.0805\n",
            "Epoch [3/10], Step [100], Loss: 1.0124\n",
            "Epoch [3/10], Step [200], Loss: 1.0137\n",
            "Epoch [3/10], Step [300], Loss: 1.0022\n",
            "Epoch [3/10], Step [400], Loss: 0.9740\n",
            "Epoch [3/10], Step [500], Loss: 0.9704\n",
            "Epoch [3/10], Step [600], Loss: 0.9607\n",
            "Epoch [3/10], Step [700], Loss: 0.9165\n",
            "Epoch [4/10], Step [100], Loss: 0.8717\n",
            "Epoch [4/10], Step [200], Loss: 0.8657\n",
            "Epoch [4/10], Step [300], Loss: 0.8977\n",
            "Epoch [4/10], Step [400], Loss: 0.8657\n",
            "Epoch [4/10], Step [500], Loss: 0.8454\n",
            "Epoch [4/10], Step [600], Loss: 0.8463\n",
            "Epoch [4/10], Step [700], Loss: 0.8460\n",
            "Epoch [5/10], Step [100], Loss: 0.8227\n",
            "Epoch [5/10], Step [200], Loss: 0.8068\n",
            "Epoch [5/10], Step [300], Loss: 0.8077\n",
            "Epoch [5/10], Step [400], Loss: 0.7714\n",
            "Epoch [5/10], Step [500], Loss: 0.7661\n",
            "Epoch [5/10], Step [600], Loss: 0.7978\n",
            "Epoch [5/10], Step [700], Loss: 0.7691\n",
            "Epoch [6/10], Step [100], Loss: 0.7730\n",
            "Epoch [6/10], Step [200], Loss: 0.7473\n",
            "Epoch [6/10], Step [300], Loss: 0.7324\n",
            "Epoch [6/10], Step [400], Loss: 0.7274\n",
            "Epoch [6/10], Step [500], Loss: 0.7603\n",
            "Epoch [6/10], Step [600], Loss: 0.7478\n",
            "Epoch [6/10], Step [700], Loss: 0.7255\n",
            "Epoch [7/10], Step [100], Loss: 0.7008\n",
            "Epoch [7/10], Step [200], Loss: 0.7218\n",
            "Epoch [7/10], Step [300], Loss: 0.7364\n",
            "Epoch [7/10], Step [400], Loss: 0.7071\n",
            "Epoch [7/10], Step [500], Loss: 0.7119\n",
            "Epoch [7/10], Step [600], Loss: 0.7126\n",
            "Epoch [7/10], Step [700], Loss: 0.7097\n",
            "Epoch [8/10], Step [100], Loss: 0.6815\n",
            "Epoch [8/10], Step [200], Loss: 0.6925\n",
            "Epoch [8/10], Step [300], Loss: 0.6614\n",
            "Epoch [8/10], Step [400], Loss: 0.6935\n",
            "Epoch [8/10], Step [500], Loss: 0.6664\n",
            "Epoch [8/10], Step [600], Loss: 0.6774\n",
            "Epoch [8/10], Step [700], Loss: 0.6682\n",
            "Epoch [9/10], Step [100], Loss: 0.6515\n",
            "Epoch [9/10], Step [200], Loss: 0.6418\n",
            "Epoch [9/10], Step [300], Loss: 0.6587\n",
            "Epoch [9/10], Step [400], Loss: 0.6624\n",
            "Epoch [9/10], Step [500], Loss: 0.6403\n",
            "Epoch [9/10], Step [600], Loss: 0.6488\n",
            "Epoch [9/10], Step [700], Loss: 0.6560\n",
            "Epoch [10/10], Step [100], Loss: 0.6154\n",
            "Epoch [10/10], Step [200], Loss: 0.6332\n",
            "Epoch [10/10], Step [300], Loss: 0.5970\n",
            "Epoch [10/10], Step [400], Loss: 0.5956\n",
            "Epoch [10/10], Step [500], Loss: 0.6434\n",
            "Epoch [10/10], Step [600], Loss: 0.6358\n",
            "Epoch [10/10], Step [700], Loss: 0.6443\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        outputs = model(images)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute the loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 100 == 99:  # Print every 100 mini-batches\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}], Loss: {running_loss/100:.4f}')\n",
        "            running_loss = 0.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gok84E8yXX8d"
      },
      "source": [
        "### Evaluating the Model\n",
        "Once the model is trained, we can evaluate its performance on the test dataset by calculating the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT-PnfPvXX8d",
        "outputId": "f1e8b1ca-dda7-4236-e7c9-9308abdfd1be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the 10,000 test images: 75.24%\n"
          ]
        }
      ],
      "source": [
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():  # No need to compute gradients during evaluation\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)  # Get the class with the highest score\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the model on the 10,000 test images: {accuracy:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG9PDbRsXX8e"
      },
      "source": [
        "### Saving and Loading the Model\n",
        "After training, we can save the model to disk and reload it later for inference or further training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pWM2_F8mXX8e"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'cnn_cifar10.pth')\n",
        "\n",
        "# To load the model later:\n",
        "# model = CNN()\n",
        "# model.load_state_dict(torch.load('cnn_cifar10.pth'))\n",
        "# model.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxkgl7TkXX8e"
      },
      "source": [
        "### Final Thoughts\n",
        "* Challenges: While CNNs are effective for image classification tasks, they require careful tuning of hyperparameters such as learning rate, batch size, and architecture complexity.\n",
        "* Future Work: Experiment with deeper models or advanced techniques like Transfer Learning to improve accuracy on CIFAR-10 or other datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kCWEEk_XX8e"
      },
      "source": [
        "## Conclusion and Next Steps\n",
        "Congratulations! You’ve built a PyTorch neural network and trained it on the CIFAR-10 dataset. Next, you can experiment with more complex datasets and models, or dive deeper into PyTorch features like:\n",
        "\n",
        "* Custom datasets\n",
        "* Advanced optimizers\n",
        "* Transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZveDezIUXX8f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S_lBMCzXX8m"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}