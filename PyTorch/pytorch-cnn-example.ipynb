{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PyTorch Beginner Tutorial\nThis tutorial will guide you through the fundamentals of PyTorch, from basic tensor operations to building and training neural networks. By the end, you’ll have built a simple convolutional neural network and trained it on the CIFAR-10 dataset.","metadata":{"id":"j8MmvtqCXX8E"}},{"cell_type":"markdown","source":"## 1. Introduction to PyTorch\n\n### What is PyTorch?\n\nPyTorch is a popular open-source deep learning framework that provides a flexible platform for research and production. It is used for building and training neural networks and offers dynamic computation graphs, which means it builds the graph on-the-fly as operations are executed. This is one of the major reasons it is widely adopted by both researchers and practitioners.\n\n### Why PyTorch?\n\n* Easy to use and debug.\n* Dynamic computation graph.\n* Seamless integration with Python.\n\n### Installation\nTo install PyTorch, follow these steps:\n\nCPU Version :\n```bash\npip install torch torchvision torchaudio\n```\nGPU Version :\n```bash\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n```","metadata":{"id":"R3lMs1J_XX8K"}},{"cell_type":"markdown","source":"## 2. Tensors and Operations\n\n### What are Tensors?\nTensors are the fundamental building blocks of PyTorch, similar to arrays in NumPy but with added functionality for GPU acceleration.\n\nCreating Tensors","metadata":{"id":"0ESZ27-GXX8L"}},{"cell_type":"code","source":"import torch\n\n# Create a tensor from a list\nx = torch.tensor([[1, 2], [3, 4]])\nprint(x)\n\n# Create a random tensor\nrandom_tensor = torch.rand(3, 3)\nprint(random_tensor)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8myDFqJ_XX8N","outputId":"afd391f3-ca37-4e64-eb68-046f9d9d2277","execution":{"iopub.status.busy":"2024-10-09T20:24:56.251901Z","iopub.execute_input":"2024-10-09T20:24:56.252774Z","iopub.status.idle":"2024-10-09T20:25:00.070581Z","shell.execute_reply.started":"2024-10-09T20:24:56.252731Z","shell.execute_reply":"2024-10-09T20:25:00.069591Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"tensor([[1, 2],\n        [3, 4]])\ntensor([[0.1028, 0.1647, 0.3589],\n        [0.7875, 0.9332, 0.4134],\n        [0.3297, 0.4527, 0.5389]])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Basic Tensor Operations\n\nTensors support various mathematical operations like addition, multiplication, and matrix multiplication.","metadata":{"id":"_-L-phtlXX8P"}},{"cell_type":"code","source":"# Element-wise addition\nx = torch.tensor([1.0, 2.0])\ny = torch.tensor([3.0, 4.0])\nz = x + y\nprint(z)\n\n# Matrix multiplication\na = torch.rand(2, 3)\nb = torch.rand(3, 2)\nresult = torch.matmul(a, b)\nprint(result)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GNVSPwoxXX8Q","outputId":"602c99a5-412a-48d3-f0d1-ec6f2748f003","execution":{"iopub.status.busy":"2024-10-09T20:25:02.399787Z","iopub.execute_input":"2024-10-09T20:25:02.400420Z","iopub.status.idle":"2024-10-09T20:25:02.467019Z","shell.execute_reply.started":"2024-10-09T20:25:02.400365Z","shell.execute_reply":"2024-10-09T20:25:02.465972Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"tensor([4., 6.])\ntensor([[1.1322, 1.1980],\n        [0.7644, 0.9101]])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Autograd: Automatic Differentiation\n\nPyTorch's autograd feature allows automatic computation of gradients for tensor operations, which is essential for training neural networks.\n\n### Example","metadata":{"id":"5N2D296fXX8Q"}},{"cell_type":"code","source":"# Define a tensor with gradient tracking\nx = torch.tensor(2.0, requires_grad=True)\n\n# Perform some operations\ny = x ** 2\n\n# Backpropagation\ny.backward()\n\n# The gradient (dy/dx)\nprint(x.grad)  # Output: 4.0\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mOV8_46ZXX8R","outputId":"124f2ea3-61c2-4e2e-8d9f-6ac82e43a479","execution":{"iopub.status.busy":"2024-10-09T20:25:04.190142Z","iopub.execute_input":"2024-10-09T20:25:04.191282Z","iopub.status.idle":"2024-10-09T20:25:04.267635Z","shell.execute_reply.started":"2024-10-09T20:25:04.191235Z","shell.execute_reply":"2024-10-09T20:25:04.266614Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"tensor(4.)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Building Neural Networks with PyTorch\n\nWe’ll now move on to constructing neural networks using PyTorch’s torch.nn module.\n\n### Creating a Simple Neural Network\nHere’s how to define a simple feedforward network with one hidden layer:","metadata":{"id":"NuFzy8R7XX8S"}},{"cell_type":"code","source":"import torch.nn as nn\n\n# Define the model\nclass SimpleNN(nn.Module):\n    def __init__(self):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(10, 50)\n        self.fc2 = nn.Linear(50, 1)\n\n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n","metadata":{"id":"F0cxutoMXX8S","execution":{"iopub.status.busy":"2024-10-09T20:25:06.229378Z","iopub.execute_input":"2024-10-09T20:25:06.230312Z","iopub.status.idle":"2024-10-09T20:25:06.239289Z","shell.execute_reply.started":"2024-10-09T20:25:06.230270Z","shell.execute_reply":"2024-10-09T20:25:06.238321Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Training a Neural Network\n### Loss Function and Optimizer\nTo train the model, we need to define a loss function and an optimizer.","metadata":{"id":"C7inQOgbXX8T"}},{"cell_type":"code","source":"model = SimpleNN()\ncriterion = nn.MSELoss()  # Mean Squared Error Loss\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","metadata":{"id":"m5nYerlhXX8T","execution":{"iopub.status.busy":"2024-10-09T20:25:08.493841Z","iopub.execute_input":"2024-10-09T20:25:08.494707Z","iopub.status.idle":"2024-10-09T20:25:10.016776Z","shell.execute_reply.started":"2024-10-09T20:25:08.494664Z","shell.execute_reply":"2024-10-09T20:25:10.015949Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Training Loop\nHere’s a simple example of a training loop:","metadata":{"id":"UIoUM_osXX8U"}},{"cell_type":"code","source":"# Example training loop\nfor epoch in range(100):\n    optimizer.zero_grad()  # Zero the gradients\n    outputs = model(torch.rand(10))  # Dummy input\n    loss = criterion(outputs, torch.rand(1))\n    loss.backward()  # Backpropagation\n    optimizer.step()  # Update weights\n\n    if epoch % 10 == 0:\n        print(f'Epoch {epoch}, Loss: {loss.item()}')\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q2sAHBilXX8V","outputId":"9691e64a-a745-4610-c4f4-a6bfd6337095","execution":{"iopub.status.busy":"2024-10-09T20:25:11.675339Z","iopub.execute_input":"2024-10-09T20:25:11.676075Z","iopub.status.idle":"2024-10-09T20:25:11.800342Z","shell.execute_reply.started":"2024-10-09T20:25:11.676033Z","shell.execute_reply":"2024-10-09T20:25:11.799464Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Epoch 0, Loss: 0.1818007528781891\nEpoch 10, Loss: 0.46184012293815613\nEpoch 20, Loss: 0.002310809213668108\nEpoch 30, Loss: 0.004846265539526939\nEpoch 40, Loss: 0.2919002175331116\nEpoch 50, Loss: 0.05440371111035347\nEpoch 60, Loss: 7.233682845253497e-05\nEpoch 70, Loss: 0.1509057879447937\nEpoch 80, Loss: 0.047387998551130295\nEpoch 90, Loss: 0.14402790367603302\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Dataset and DataLoader\n### Loading a Dataset\nPyTorch provides utilities for loading datasets and creating batches using DataLoader. Let’s load the MNIST dataset.","metadata":{"id":"Llt4GoPPXX8W"}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torchvision.datasets import MNIST\nfrom torchvision.transforms import ToTensor\n\ntrain_data = MNIST(root='data', train=True, transform=ToTensor(), download=True)\ntrain_loader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lhWMYb0lXX8X","outputId":"d323a5bf-4b73-4362-9e4e-ea15bb14db3a","execution":{"iopub.status.busy":"2024-10-09T20:25:14.088627Z","iopub.execute_input":"2024-10-09T20:25:14.089535Z","iopub.status.idle":"2024-10-09T20:25:17.564788Z","shell.execute_reply.started":"2024-10-09T20:25:14.089469Z","shell.execute_reply":"2024-10-09T20:25:17.562825Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 34066500.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 1059276.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 9685376.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 2420344.15it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## GPU Support\nTraining on a GPU can significantly speed up the process.","metadata":{"id":"sYfm1xGGXX8Y"}},{"cell_type":"code","source":"# Check for GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Move model and data to GPU\nmodel = SimpleNN().to(device)\nx = torch.rand(10).to(device)\n","metadata":{"id":"TfkmA5yRXX8Y","execution":{"iopub.status.busy":"2024-10-09T20:25:19.716181Z","iopub.execute_input":"2024-10-09T20:25:19.717397Z","iopub.status.idle":"2024-10-09T20:25:19.904602Z","shell.execute_reply.started":"2024-10-09T20:25:19.717324Z","shell.execute_reply":"2024-10-09T20:25:19.903819Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Saving and Loading Models\nSaving the Model","metadata":{"id":"8IDOW2MYXX8Z"}},{"cell_type":"code","source":"torch.save(model.state_dict(), 'model.pth')\n","metadata":{"id":"w3vCWbJzXX8Z","execution":{"iopub.status.busy":"2024-10-09T20:25:21.788442Z","iopub.execute_input":"2024-10-09T20:25:21.789362Z","iopub.status.idle":"2024-10-09T20:25:21.797628Z","shell.execute_reply.started":"2024-10-09T20:25:21.789319Z","shell.execute_reply":"2024-10-09T20:25:21.796712Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Loading the model","metadata":{"id":"GzC8pux9XX8Z"}},{"cell_type":"code","source":"model.load_state_dict(torch.load('model.pth'))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fWLYM6tlXX8a","outputId":"7d747f92-2085-4327-f5f4-ba9b5d125fcf","execution":{"iopub.status.busy":"2024-10-09T20:25:25.948611Z","iopub.execute_input":"2024-10-09T20:25:25.948998Z","iopub.status.idle":"2024-10-09T20:25:25.960277Z","shell.execute_reply.started":"2024-10-09T20:25:25.948964Z","shell.execute_reply":"2024-10-09T20:25:25.959289Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/165183459.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('model.pth'))\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"markdown","source":"## End-to-End Example: CIFAR-10 Image Classification with CNN\n### Overview\nIn this section, we will build, train, and evaluate a Convolutional Neural Network (CNN) to classify images from the CIFAR-10 dataset. This project will showcase how to use PyTorch for more complex data and how to optimize model training using techniques like data augmentation and GPU acceleration.\n\n### Step 1: Loading and Preprocessing the CIFAR-10 Dataset\nWe’ll start by loading the CIFAR-10 dataset using PyTorch’s torchvision module and apply transformations like normalization and data augmentation to improve model performance.","metadata":{"id":"0CE-J2dcXX8a"}},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\n\n# Define transformations including normalization and data augmentation (random cropping, flipping)\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n    transforms.RandomCrop(32, padding=4),  # Randomly crop the image\n    transforms.ToTensor(),  # Convert the image to a tensor\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize based on CIFAR-10 stats\n])\n\n\n\n# Load the dataset\ntrain_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntest_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n\n# Create data loaders\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True, num_workers=2)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False, num_workers=2)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hJXa1KtGXX8a","outputId":"f01b86a2-bc34-4fb6-d5e5-e6584b1f57e8","execution":{"iopub.status.busy":"2024-10-09T20:25:28.672695Z","iopub.execute_input":"2024-10-09T20:25:28.673049Z","iopub.status.idle":"2024-10-09T20:25:33.847263Z","shell.execute_reply.started":"2024-10-09T20:25:28.673018Z","shell.execute_reply":"2024-10-09T20:25:33.846317Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:01<00:00, 101076407.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Step 2: Building the CNN Model\nWe will now define a simple CNN architecture to handle image classification. This model will include convolutional layers for feature extraction and fully connected layers for classification.","metadata":{"id":"AsdoPRDSXX8b"}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n# Define the CNN model\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        # Convolutional layers\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n\n        # Fully connected layers\n        self.fc1 = nn.Linear(128 * 4 * 4, 256)  # 128 feature maps, each 4x4 after pooling\n        self.fc2 = nn.Linear(256, 10)  # 10 output classes (CIFAR-10 classes)\n\n    def forward(self, x):\n        # Apply convolution, ReLU, and max pooling layers\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x, 2)\n\n        # Flatten the tensor\n        x = x.view(x.size(0), -1)\n\n        # Apply fully connected layers\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n\n        return x\n","metadata":{"id":"IMIppVJRXX8b","execution":{"iopub.status.busy":"2024-10-09T20:25:33.848762Z","iopub.execute_input":"2024-10-09T20:25:33.849077Z","iopub.status.idle":"2024-10-09T20:25:33.858752Z","shell.execute_reply.started":"2024-10-09T20:25:33.849044Z","shell.execute_reply":"2024-10-09T20:25:33.857754Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Step 3: Setting the Loss Function and Optimizer\nWe will use the CrossEntropyLoss for classification and Adam as the optimizer to update the model’s weights.","metadata":{"id":"YLr72-2EXX8b"}},{"cell_type":"code","source":"import torch.optim as optim\n\nmodel = CNN()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n","metadata":{"id":"XVl1veVzXX8c","execution":{"iopub.status.busy":"2024-10-09T20:25:36.640052Z","iopub.execute_input":"2024-10-09T20:25:36.640547Z","iopub.status.idle":"2024-10-09T20:25:36.652626Z","shell.execute_reply.started":"2024-10-09T20:25:36.640476Z","shell.execute_reply":"2024-10-09T20:25:36.651699Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Step 4: Training the Model\nWe’ll now define the training loop. This loop will:\n\n* Iterate over the training data.\n* Compute the loss and gradients.\n* Update the model weights using backpropagation.\n* Track the loss for monitoring.","metadata":{"id":"Nngs2ca-XX8c"}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\n# Training loop\nnum_epochs = 50\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n\n    for i, (images, labels) in enumerate(train_loader):\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()  # Zero the gradients\n        outputs = model(images)  # Forward pass\n        loss = criterion(outputs, labels)  # Compute the loss\n        loss.backward()  # Backpropagation\n        optimizer.step()  # Update weights\n\n        running_loss += loss.item()\n\n        if i % 100 == 99:  # Print every 100 mini-batches\n            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}], Loss: {running_loss/100:.4f}')\n            running_loss = 0.0\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y_QP7Z_HXX8d","outputId":"448769d6-49e7-4f0a-e3f6-8ac290b1cba4","execution":{"iopub.status.busy":"2024-10-09T20:25:38.797974Z","iopub.execute_input":"2024-10-09T20:25:38.798688Z","iopub.status.idle":"2024-10-09T20:36:50.615640Z","shell.execute_reply.started":"2024-10-09T20:25:38.798648Z","shell.execute_reply":"2024-10-09T20:36:50.614532Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch [1/50], Step [100], Loss: 1.9832\nEpoch [1/50], Step [200], Loss: 1.7155\nEpoch [1/50], Step [300], Loss: 1.5699\nEpoch [1/50], Step [400], Loss: 1.5121\nEpoch [1/50], Step [500], Loss: 1.4827\nEpoch [1/50], Step [600], Loss: 1.4244\nEpoch [1/50], Step [700], Loss: 1.3767\nEpoch [2/50], Step [100], Loss: 1.2884\nEpoch [2/50], Step [200], Loss: 1.2303\nEpoch [2/50], Step [300], Loss: 1.2106\nEpoch [2/50], Step [400], Loss: 1.1932\nEpoch [2/50], Step [500], Loss: 1.1693\nEpoch [2/50], Step [600], Loss: 1.1259\nEpoch [2/50], Step [700], Loss: 1.1138\nEpoch [3/50], Step [100], Loss: 1.0613\nEpoch [3/50], Step [200], Loss: 1.0539\nEpoch [3/50], Step [300], Loss: 1.0102\nEpoch [3/50], Step [400], Loss: 0.9991\nEpoch [3/50], Step [500], Loss: 0.9978\nEpoch [3/50], Step [600], Loss: 0.9764\nEpoch [3/50], Step [700], Loss: 0.9199\nEpoch [4/50], Step [100], Loss: 0.8976\nEpoch [4/50], Step [200], Loss: 0.8880\nEpoch [4/50], Step [300], Loss: 0.8804\nEpoch [4/50], Step [400], Loss: 0.8741\nEpoch [4/50], Step [500], Loss: 0.8976\nEpoch [4/50], Step [600], Loss: 0.8660\nEpoch [4/50], Step [700], Loss: 0.8537\nEpoch [5/50], Step [100], Loss: 0.8129\nEpoch [5/50], Step [200], Loss: 0.8294\nEpoch [5/50], Step [300], Loss: 0.8260\nEpoch [5/50], Step [400], Loss: 0.8109\nEpoch [5/50], Step [500], Loss: 0.7861\nEpoch [5/50], Step [600], Loss: 0.8049\nEpoch [5/50], Step [700], Loss: 0.8278\nEpoch [6/50], Step [100], Loss: 0.7526\nEpoch [6/50], Step [200], Loss: 0.7870\nEpoch [6/50], Step [300], Loss: 0.7701\nEpoch [6/50], Step [400], Loss: 0.7496\nEpoch [6/50], Step [500], Loss: 0.7394\nEpoch [6/50], Step [600], Loss: 0.7426\nEpoch [6/50], Step [700], Loss: 0.7246\nEpoch [7/50], Step [100], Loss: 0.7236\nEpoch [7/50], Step [200], Loss: 0.7019\nEpoch [7/50], Step [300], Loss: 0.7299\nEpoch [7/50], Step [400], Loss: 0.7064\nEpoch [7/50], Step [500], Loss: 0.7183\nEpoch [7/50], Step [600], Loss: 0.7060\nEpoch [7/50], Step [700], Loss: 0.6943\nEpoch [8/50], Step [100], Loss: 0.6542\nEpoch [8/50], Step [200], Loss: 0.6650\nEpoch [8/50], Step [300], Loss: 0.6849\nEpoch [8/50], Step [400], Loss: 0.6822\nEpoch [8/50], Step [500], Loss: 0.6698\nEpoch [8/50], Step [600], Loss: 0.6511\nEpoch [8/50], Step [700], Loss: 0.6912\nEpoch [9/50], Step [100], Loss: 0.6487\nEpoch [9/50], Step [200], Loss: 0.6469\nEpoch [9/50], Step [300], Loss: 0.6330\nEpoch [9/50], Step [400], Loss: 0.6385\nEpoch [9/50], Step [500], Loss: 0.6571\nEpoch [9/50], Step [600], Loss: 0.6467\nEpoch [9/50], Step [700], Loss: 0.6364\nEpoch [10/50], Step [100], Loss: 0.6188\nEpoch [10/50], Step [200], Loss: 0.6166\nEpoch [10/50], Step [300], Loss: 0.6167\nEpoch [10/50], Step [400], Loss: 0.6349\nEpoch [10/50], Step [500], Loss: 0.6269\nEpoch [10/50], Step [600], Loss: 0.6332\nEpoch [10/50], Step [700], Loss: 0.6082\nEpoch [11/50], Step [100], Loss: 0.6023\nEpoch [11/50], Step [200], Loss: 0.6049\nEpoch [11/50], Step [300], Loss: 0.5959\nEpoch [11/50], Step [400], Loss: 0.6450\nEpoch [11/50], Step [500], Loss: 0.5854\nEpoch [11/50], Step [600], Loss: 0.5966\nEpoch [11/50], Step [700], Loss: 0.5876\nEpoch [12/50], Step [100], Loss: 0.5707\nEpoch [12/50], Step [200], Loss: 0.5899\nEpoch [12/50], Step [300], Loss: 0.5869\nEpoch [12/50], Step [400], Loss: 0.5654\nEpoch [12/50], Step [500], Loss: 0.5734\nEpoch [12/50], Step [600], Loss: 0.5999\nEpoch [12/50], Step [700], Loss: 0.5906\nEpoch [13/50], Step [100], Loss: 0.5587\nEpoch [13/50], Step [200], Loss: 0.5708\nEpoch [13/50], Step [300], Loss: 0.5754\nEpoch [13/50], Step [400], Loss: 0.5724\nEpoch [13/50], Step [500], Loss: 0.5733\nEpoch [13/50], Step [600], Loss: 0.5703\nEpoch [13/50], Step [700], Loss: 0.5940\nEpoch [14/50], Step [100], Loss: 0.5636\nEpoch [14/50], Step [200], Loss: 0.5474\nEpoch [14/50], Step [300], Loss: 0.5260\nEpoch [14/50], Step [400], Loss: 0.5429\nEpoch [14/50], Step [500], Loss: 0.5349\nEpoch [14/50], Step [600], Loss: 0.5420\nEpoch [14/50], Step [700], Loss: 0.5330\nEpoch [15/50], Step [100], Loss: 0.5455\nEpoch [15/50], Step [200], Loss: 0.5093\nEpoch [15/50], Step [300], Loss: 0.5218\nEpoch [15/50], Step [400], Loss: 0.5537\nEpoch [15/50], Step [500], Loss: 0.5267\nEpoch [15/50], Step [600], Loss: 0.5318\nEpoch [15/50], Step [700], Loss: 0.5281\nEpoch [16/50], Step [100], Loss: 0.5110\nEpoch [16/50], Step [200], Loss: 0.5128\nEpoch [16/50], Step [300], Loss: 0.5214\nEpoch [16/50], Step [400], Loss: 0.5149\nEpoch [16/50], Step [500], Loss: 0.5164\nEpoch [16/50], Step [600], Loss: 0.5382\nEpoch [16/50], Step [700], Loss: 0.5183\nEpoch [17/50], Step [100], Loss: 0.4818\nEpoch [17/50], Step [200], Loss: 0.4961\nEpoch [17/50], Step [300], Loss: 0.5295\nEpoch [17/50], Step [400], Loss: 0.5027\nEpoch [17/50], Step [500], Loss: 0.5199\nEpoch [17/50], Step [600], Loss: 0.5130\nEpoch [17/50], Step [700], Loss: 0.5242\nEpoch [18/50], Step [100], Loss: 0.4827\nEpoch [18/50], Step [200], Loss: 0.4725\nEpoch [18/50], Step [300], Loss: 0.4943\nEpoch [18/50], Step [400], Loss: 0.5088\nEpoch [18/50], Step [500], Loss: 0.5016\nEpoch [18/50], Step [600], Loss: 0.5124\nEpoch [18/50], Step [700], Loss: 0.4920\nEpoch [19/50], Step [100], Loss: 0.4913\nEpoch [19/50], Step [200], Loss: 0.4723\nEpoch [19/50], Step [300], Loss: 0.4779\nEpoch [19/50], Step [400], Loss: 0.5086\nEpoch [19/50], Step [500], Loss: 0.4950\nEpoch [19/50], Step [600], Loss: 0.5051\nEpoch [19/50], Step [700], Loss: 0.4922\nEpoch [20/50], Step [100], Loss: 0.4612\nEpoch [20/50], Step [200], Loss: 0.4747\nEpoch [20/50], Step [300], Loss: 0.4740\nEpoch [20/50], Step [400], Loss: 0.4606\nEpoch [20/50], Step [500], Loss: 0.4990\nEpoch [20/50], Step [600], Loss: 0.4860\nEpoch [20/50], Step [700], Loss: 0.4743\nEpoch [21/50], Step [100], Loss: 0.4705\nEpoch [21/50], Step [200], Loss: 0.4774\nEpoch [21/50], Step [300], Loss: 0.4754\nEpoch [21/50], Step [400], Loss: 0.4686\nEpoch [21/50], Step [500], Loss: 0.4772\nEpoch [21/50], Step [600], Loss: 0.4605\nEpoch [21/50], Step [700], Loss: 0.4820\nEpoch [22/50], Step [100], Loss: 0.4529\nEpoch [22/50], Step [200], Loss: 0.4576\nEpoch [22/50], Step [300], Loss: 0.4596\nEpoch [22/50], Step [400], Loss: 0.4547\nEpoch [22/50], Step [500], Loss: 0.4700\nEpoch [22/50], Step [600], Loss: 0.4806\nEpoch [22/50], Step [700], Loss: 0.4568\nEpoch [23/50], Step [100], Loss: 0.4328\nEpoch [23/50], Step [200], Loss: 0.4453\nEpoch [23/50], Step [300], Loss: 0.4613\nEpoch [23/50], Step [400], Loss: 0.4472\nEpoch [23/50], Step [500], Loss: 0.4668\nEpoch [23/50], Step [600], Loss: 0.4576\nEpoch [23/50], Step [700], Loss: 0.4619\nEpoch [24/50], Step [100], Loss: 0.4298\nEpoch [24/50], Step [200], Loss: 0.4344\nEpoch [24/50], Step [300], Loss: 0.4564\nEpoch [24/50], Step [400], Loss: 0.4335\nEpoch [24/50], Step [500], Loss: 0.4378\nEpoch [24/50], Step [600], Loss: 0.4557\nEpoch [24/50], Step [700], Loss: 0.4548\nEpoch [25/50], Step [100], Loss: 0.4233\nEpoch [25/50], Step [200], Loss: 0.4547\nEpoch [25/50], Step [300], Loss: 0.4473\nEpoch [25/50], Step [400], Loss: 0.4218\nEpoch [25/50], Step [500], Loss: 0.4687\nEpoch [25/50], Step [600], Loss: 0.4349\nEpoch [25/50], Step [700], Loss: 0.4528\nEpoch [26/50], Step [100], Loss: 0.4148\nEpoch [26/50], Step [200], Loss: 0.4209\nEpoch [26/50], Step [300], Loss: 0.4191\nEpoch [26/50], Step [400], Loss: 0.4415\nEpoch [26/50], Step [500], Loss: 0.4341\nEpoch [26/50], Step [600], Loss: 0.4298\nEpoch [26/50], Step [700], Loss: 0.4474\nEpoch [27/50], Step [100], Loss: 0.4044\nEpoch [27/50], Step [200], Loss: 0.4318\nEpoch [27/50], Step [300], Loss: 0.4154\nEpoch [27/50], Step [400], Loss: 0.4432\nEpoch [27/50], Step [500], Loss: 0.4277\nEpoch [27/50], Step [600], Loss: 0.4298\nEpoch [27/50], Step [700], Loss: 0.4405\nEpoch [28/50], Step [100], Loss: 0.3875\nEpoch [28/50], Step [200], Loss: 0.4138\nEpoch [28/50], Step [300], Loss: 0.4107\nEpoch [28/50], Step [400], Loss: 0.4184\nEpoch [28/50], Step [500], Loss: 0.4153\nEpoch [28/50], Step [600], Loss: 0.4250\nEpoch [28/50], Step [700], Loss: 0.4169\nEpoch [29/50], Step [100], Loss: 0.4020\nEpoch [29/50], Step [200], Loss: 0.4297\nEpoch [29/50], Step [300], Loss: 0.4141\nEpoch [29/50], Step [400], Loss: 0.4318\nEpoch [29/50], Step [500], Loss: 0.4241\nEpoch [29/50], Step [600], Loss: 0.4103\nEpoch [29/50], Step [700], Loss: 0.4228\nEpoch [30/50], Step [100], Loss: 0.3999\nEpoch [30/50], Step [200], Loss: 0.4077\nEpoch [30/50], Step [300], Loss: 0.4081\nEpoch [30/50], Step [400], Loss: 0.4185\nEpoch [30/50], Step [500], Loss: 0.4145\nEpoch [30/50], Step [600], Loss: 0.3982\nEpoch [30/50], Step [700], Loss: 0.4127\nEpoch [31/50], Step [100], Loss: 0.3914\nEpoch [31/50], Step [200], Loss: 0.3853\nEpoch [31/50], Step [300], Loss: 0.4312\nEpoch [31/50], Step [400], Loss: 0.4062\nEpoch [31/50], Step [500], Loss: 0.4101\nEpoch [31/50], Step [600], Loss: 0.4251\nEpoch [31/50], Step [700], Loss: 0.4133\nEpoch [32/50], Step [100], Loss: 0.3755\nEpoch [32/50], Step [200], Loss: 0.4060\nEpoch [32/50], Step [300], Loss: 0.4010\nEpoch [32/50], Step [400], Loss: 0.3928\nEpoch [32/50], Step [500], Loss: 0.4031\nEpoch [32/50], Step [600], Loss: 0.4056\nEpoch [32/50], Step [700], Loss: 0.3957\nEpoch [33/50], Step [100], Loss: 0.3846\nEpoch [33/50], Step [200], Loss: 0.3785\nEpoch [33/50], Step [300], Loss: 0.4282\nEpoch [33/50], Step [400], Loss: 0.4091\nEpoch [33/50], Step [500], Loss: 0.3931\nEpoch [33/50], Step [600], Loss: 0.4117\nEpoch [33/50], Step [700], Loss: 0.3873\nEpoch [34/50], Step [100], Loss: 0.3926\nEpoch [34/50], Step [200], Loss: 0.3920\nEpoch [34/50], Step [300], Loss: 0.3829\nEpoch [34/50], Step [400], Loss: 0.3907\nEpoch [34/50], Step [500], Loss: 0.3855\nEpoch [34/50], Step [600], Loss: 0.3990\nEpoch [34/50], Step [700], Loss: 0.4065\nEpoch [35/50], Step [100], Loss: 0.3583\nEpoch [35/50], Step [200], Loss: 0.3599\nEpoch [35/50], Step [300], Loss: 0.3759\nEpoch [35/50], Step [400], Loss: 0.3840\nEpoch [35/50], Step [500], Loss: 0.3932\nEpoch [35/50], Step [600], Loss: 0.3912\nEpoch [35/50], Step [700], Loss: 0.3922\nEpoch [36/50], Step [100], Loss: 0.3741\nEpoch [36/50], Step [200], Loss: 0.3805\nEpoch [36/50], Step [300], Loss: 0.3750\nEpoch [36/50], Step [400], Loss: 0.3997\nEpoch [36/50], Step [500], Loss: 0.3928\nEpoch [36/50], Step [600], Loss: 0.3751\nEpoch [36/50], Step [700], Loss: 0.3781\nEpoch [37/50], Step [100], Loss: 0.3568\nEpoch [37/50], Step [200], Loss: 0.3647\nEpoch [37/50], Step [300], Loss: 0.3609\nEpoch [37/50], Step [400], Loss: 0.3641\nEpoch [37/50], Step [500], Loss: 0.3745\nEpoch [37/50], Step [600], Loss: 0.4039\nEpoch [37/50], Step [700], Loss: 0.3915\nEpoch [38/50], Step [100], Loss: 0.3663\nEpoch [38/50], Step [200], Loss: 0.3627\nEpoch [38/50], Step [300], Loss: 0.3761\nEpoch [38/50], Step [400], Loss: 0.3596\nEpoch [38/50], Step [500], Loss: 0.3816\nEpoch [38/50], Step [600], Loss: 0.3636\nEpoch [38/50], Step [700], Loss: 0.3798\nEpoch [39/50], Step [100], Loss: 0.3688\nEpoch [39/50], Step [200], Loss: 0.3629\nEpoch [39/50], Step [300], Loss: 0.3650\nEpoch [39/50], Step [400], Loss: 0.3564\nEpoch [39/50], Step [500], Loss: 0.3840\nEpoch [39/50], Step [600], Loss: 0.3793\nEpoch [39/50], Step [700], Loss: 0.3719\nEpoch [40/50], Step [100], Loss: 0.3656\nEpoch [40/50], Step [200], Loss: 0.3584\nEpoch [40/50], Step [300], Loss: 0.3487\nEpoch [40/50], Step [400], Loss: 0.3605\nEpoch [40/50], Step [500], Loss: 0.3771\nEpoch [40/50], Step [600], Loss: 0.3652\nEpoch [40/50], Step [700], Loss: 0.3817\nEpoch [41/50], Step [100], Loss: 0.3626\nEpoch [41/50], Step [200], Loss: 0.3654\nEpoch [41/50], Step [300], Loss: 0.3624\nEpoch [41/50], Step [400], Loss: 0.3609\nEpoch [41/50], Step [500], Loss: 0.3545\nEpoch [41/50], Step [600], Loss: 0.3691\nEpoch [41/50], Step [700], Loss: 0.3428\nEpoch [42/50], Step [100], Loss: 0.3422\nEpoch [42/50], Step [200], Loss: 0.3339\nEpoch [42/50], Step [300], Loss: 0.3681\nEpoch [42/50], Step [400], Loss: 0.3742\nEpoch [42/50], Step [500], Loss: 0.3555\nEpoch [42/50], Step [600], Loss: 0.3632\nEpoch [42/50], Step [700], Loss: 0.3600\nEpoch [43/50], Step [100], Loss: 0.3450\nEpoch [43/50], Step [200], Loss: 0.3430\nEpoch [43/50], Step [300], Loss: 0.3383\nEpoch [43/50], Step [400], Loss: 0.3537\nEpoch [43/50], Step [500], Loss: 0.3686\nEpoch [43/50], Step [600], Loss: 0.3678\nEpoch [43/50], Step [700], Loss: 0.3616\nEpoch [44/50], Step [100], Loss: 0.3361\nEpoch [44/50], Step [200], Loss: 0.3438\nEpoch [44/50], Step [300], Loss: 0.3438\nEpoch [44/50], Step [400], Loss: 0.3607\nEpoch [44/50], Step [500], Loss: 0.3641\nEpoch [44/50], Step [600], Loss: 0.3561\nEpoch [44/50], Step [700], Loss: 0.3737\nEpoch [45/50], Step [100], Loss: 0.3326\nEpoch [45/50], Step [200], Loss: 0.3282\nEpoch [45/50], Step [300], Loss: 0.3615\nEpoch [45/50], Step [400], Loss: 0.3465\nEpoch [45/50], Step [500], Loss: 0.3592\nEpoch [45/50], Step [600], Loss: 0.3621\nEpoch [45/50], Step [700], Loss: 0.3600\nEpoch [46/50], Step [100], Loss: 0.3397\nEpoch [46/50], Step [200], Loss: 0.3455\nEpoch [46/50], Step [300], Loss: 0.3475\nEpoch [46/50], Step [400], Loss: 0.3475\nEpoch [46/50], Step [500], Loss: 0.3537\nEpoch [46/50], Step [600], Loss: 0.3428\nEpoch [46/50], Step [700], Loss: 0.3508\nEpoch [47/50], Step [100], Loss: 0.3517\nEpoch [47/50], Step [200], Loss: 0.3304\nEpoch [47/50], Step [300], Loss: 0.3308\nEpoch [47/50], Step [400], Loss: 0.3245\nEpoch [47/50], Step [500], Loss: 0.3476\nEpoch [47/50], Step [600], Loss: 0.3578\nEpoch [47/50], Step [700], Loss: 0.3518\nEpoch [48/50], Step [100], Loss: 0.3376\nEpoch [48/50], Step [200], Loss: 0.3313\nEpoch [48/50], Step [300], Loss: 0.3527\nEpoch [48/50], Step [400], Loss: 0.3444\nEpoch [48/50], Step [500], Loss: 0.3397\nEpoch [48/50], Step [600], Loss: 0.3534\nEpoch [48/50], Step [700], Loss: 0.3384\nEpoch [49/50], Step [100], Loss: 0.3075\nEpoch [49/50], Step [200], Loss: 0.3218\nEpoch [49/50], Step [300], Loss: 0.3333\nEpoch [49/50], Step [400], Loss: 0.3368\nEpoch [49/50], Step [500], Loss: 0.3599\nEpoch [49/50], Step [600], Loss: 0.3369\nEpoch [49/50], Step [700], Loss: 0.3597\nEpoch [50/50], Step [100], Loss: 0.3427\nEpoch [50/50], Step [200], Loss: 0.3269\nEpoch [50/50], Step [300], Loss: 0.3336\nEpoch [50/50], Step [400], Loss: 0.3265\nEpoch [50/50], Step [500], Loss: 0.3370\nEpoch [50/50], Step [600], Loss: 0.3345\nEpoch [50/50], Step [700], Loss: 0.3374\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Evaluating the Model\nOnce the model is trained, we can evaluate its performance on the test dataset by calculating the accuracy.","metadata":{"id":"gok84E8yXX8d"}},{"cell_type":"code","source":"model.eval()  # Set the model to evaluation mode\n\ncorrect = 0\ntotal = 0\nwith torch.no_grad():  # No need to compute gradients during evaluation\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)  # Get the class with the highest score\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\naccuracy = 100 * correct / total\nprint(f'Accuracy of the model on the 10,000 test images: {accuracy:.2f}%')\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vT-PnfPvXX8d","outputId":"646869ac-d62c-4949-e8a7-567472fa527b","execution":{"iopub.status.busy":"2024-10-09T20:51:04.214528Z","iopub.execute_input":"2024-10-09T20:51:04.215486Z","iopub.status.idle":"2024-10-09T20:51:07.030059Z","shell.execute_reply.started":"2024-10-09T20:51:04.215444Z","shell.execute_reply":"2024-10-09T20:51:07.028975Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Accuracy of the model on the 10,000 test images: 80.40%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Saving and Loading the Model\nAfter training, we can save the model to disk and reload it later for inference or further training.","metadata":{"id":"gG9PDbRsXX8e"}},{"cell_type":"code","source":"# Save the model\ntorch.save(model.state_dict(), 'cnn_cifar10.pth')\n\n# To load the model later:\n# model = CNN()\n# model.load_state_dict(torch.load('cnn_cifar10.pth'))\n# model.to(device)\n","metadata":{"id":"pWM2_F8mXX8e","execution":{"iopub.status.busy":"2024-10-09T20:51:13.436622Z","iopub.execute_input":"2024-10-09T20:51:13.437460Z","iopub.status.idle":"2024-10-09T20:51:13.451294Z","shell.execute_reply.started":"2024-10-09T20:51:13.437415Z","shell.execute_reply":"2024-10-09T20:51:13.449969Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### Final Thoughts\n* Challenges: While CNNs are effective for image classification tasks, they require careful tuning of hyperparameters such as learning rate, batch size, and architecture complexity.\n* Future Work: Experiment with deeper models or advanced techniques like Transfer Learning to improve accuracy on CIFAR-10 or other datasets.","metadata":{"id":"wxkgl7TkXX8e"}},{"cell_type":"markdown","source":"## Conclusion and Next Steps\nCongratulations! You’ve built a PyTorch neural network and trained it on the CIFAR-10 dataset. Next, you can experiment with more complex datasets and models, or dive deeper into PyTorch features like:\n\n* Custom datasets\n* Advanced optimizers\n* Transfer learning","metadata":{"id":"2kCWEEk_XX8e"}}]}